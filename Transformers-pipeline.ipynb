{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:35:53.405623Z","iopub.execute_input":"2024-05-13T20:35:53.405950Z","iopub.status.idle":"2024-05-13T20:36:07.335206Z","shell.execute_reply.started":"2024-05-13T20:35:53.405922Z","shell.execute_reply":"2024-05-13T20:36:07.334085Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:07.337515Z","iopub.execute_input":"2024-05-13T20:36:07.337907Z","iopub.status.idle":"2024-05-13T20:36:27.094050Z","shell.execute_reply.started":"2024-05-13T20:36:07.337868Z","shell.execute_reply":"2024-05-13T20:36:27.093267Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-13 20:36:15.382328: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 20:36:15.382421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 20:36:15.540447: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Translation","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator = pipeline(\"translation_en_to_de\")\nprint(translator(\"\"\"In response to an Irish Times editorial on April 11 on the Lok Sabha elections, India’s ambassador to Ireland, Akhilesh Mishra, wrote an extraordinary letter carried by the newspaper on April 15. It is unprecedented in the annals of the Indian Foreign Service (IFS), especially in the context of the country amidst elections. Mishra is a secretary-rank officer and cannot be dismissed as an inexperienced official seeking to win brownie points. Therefore, his fulsome praise of the persona of Prime Minister Narendra Modi, his swipe at “a single dynastic party” ruling India for the first 30 years after independence and the party’s role in entrenching an “ecosystem of corruption” was bound to become politically controversial, which it did.\n\nThe Congress has strongly objected to Mishra’s letter while the ruling dispensation has maintained a studied silence. This may be considered as part of the pull and push of the condition of India’s current electoral politics. However, beyond the political territory, Mishra’s letter raises a host of very disturbing questions that go to the core of the IFS’s ethos and the functioning of India’s institutional structures. Surprisingly, IFS’s leadership has not publicly responded to Mishra’s grave indiscretion. Nor, for that matter has the Election Commission of India (ECI). But, first The Irish Times letter and Mishra’s reply to it.\n\"\"\", max_length=40))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:27.095124Z","iopub.execute_input":"2024-05-13T20:36:27.095640Z","iopub.status.idle":"2024-05-13T20:36:38.267711Z","shell.execute_reply.started":"2024-05-13T20:36:27.095615Z","shell.execute_reply":"2024-05-13T20:36:38.266744Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd207e23536a4b259955d0126ba65612"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82a649cd3399486386264d9602f1cea1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f15ad253f4b4e4dad4223b9c6766dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"facb9d39a2d6434fb1e84972334a4d0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fb304489a7f4a08b4b0f6564a0bf906"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\nYour input_length: 332 is bigger than 0.9 * max_length: 40. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n","output_type":"stream"},{"name":"stdout","text":"[{'translation_text': 'In Reaktion auf ein Leitartikel der Irish Times vom 11. April über die Lok Sabha-Wahlen schrieb Indiens Botschafter in Irland, Akhilesh Mish'}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"classifier1 = pipeline(\"sentiment-analysis\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:38.270341Z","iopub.execute_input":"2024-05-13T20:36:38.270956Z","iopub.status.idle":"2024-05-13T20:36:40.564868Z","shell.execute_reply.started":"2024-05-13T20:36:38.270921Z","shell.execute_reply":"2024-05-13T20:36:40.564098Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"262552e664484047b12a4246ed160273"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"025b01aa1f7a4511bf7b56a347a30d54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9ce845b35584adeb3d53a4f56aff07d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cedeb744b5d4443e89a979672c990a5f"}},"metadata":{}}]},{"cell_type":"code","source":"sequences1 = [\"I love you\", \"I hate you\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:40.565849Z","iopub.execute_input":"2024-05-13T20:36:40.566115Z","iopub.status.idle":"2024-05-13T20:36:40.570847Z","shell.execute_reply.started":"2024-05-13T20:36:40.566092Z","shell.execute_reply":"2024-05-13T20:36:40.569350Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"classifier1(sequences1)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:40.572076Z","iopub.execute_input":"2024-05-13T20:36:40.572392Z","iopub.status.idle":"2024-05-13T20:36:42.591542Z","shell.execute_reply.started":"2024-05-13T20:36:40.572363Z","shell.execute_reply":"2024-05-13T20:36:42.590764Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"},"metadata":{}}]},{"cell_type":"code","source":"classifier2 = pipeline(\"sentiment-analysis\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:42.592592Z","iopub.execute_input":"2024-05-13T20:36:42.593937Z","iopub.status.idle":"2024-05-13T20:36:42.842131Z","shell.execute_reply.started":"2024-05-13T20:36:42.593910Z","shell.execute_reply":"2024-05-13T20:36:42.841191Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"}]},{"cell_type":"code","source":"sequences2 = [\"\"\"A group of Africans allegedly assaulted sleuths from the Central Crime Branch (CCB), Bengaluru City Police, who were in the process of arresting one of them for drug peddling, and also local police personnel who came to rescue their colleagues at Mavallipura, \n              near Rajanukunte on the outskirts of the city, on the night of April 18. Four police personnel sustained minor injuries and are being treated at a private hospital in Bengaluru. All the Africans are on the run. Rajanukunte police have registered a case.\n              Sleuths from the anti-narcotics wing of the CCB, Bengaluru had arrested an African from Bagalagunte on April 6 and seized 4 kg of MDMA crystals from his house worth ₹4 crore. According to the police, the accused was buying MDMA crystals from Africa, \n              got them delivered to Bengaluru, and used to sell them for ₹8,000 - ₹10,000 to his contacts in the city. On April 18, four CCB officials, led by Sumbramanya Swamy, the Investigation Officer (IO), went to Mavallipura to apprehend an associate of the person they had arrested on April 6. \n              Mallikarjun Baladandi, SP, Bengaluru Rural district, said Our team caught up with the suspect while he was on his way to his home in the village after having dinner at a restaurant nearby. They took him to his home to get hold of the drugs he had stashed away. \n              When the police team entered the rented accommodation in Mavallipura, there was another person in the house. The duo ganged up and started assaulting the police team.In the melee, one of the Africans sent out a voice note on WhatsApp. Within no time, a gang of around 10 persons gathered. The police team was overpowered. \n              The Africans hurled stones at the police. Though a Hoysala vehicle rushed to the spot, they were also attacked with stones. Our driver was injured. But they rescued the CCB team and left the spot.” \n              As the police teams withdrew from the scene, the gang of Africans fled the village.We are searching for the Africans involved in the assault on our personnel. The house is owned by a person from Bihar who had given the premises on rent three months ago to two Africans without verifying their documents, Mr. Baladandi said.\"\"\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:42.843401Z","iopub.execute_input":"2024-05-13T20:36:42.843685Z","iopub.status.idle":"2024-05-13T20:36:42.849504Z","shell.execute_reply.started":"2024-05-13T20:36:42.843661Z","shell.execute_reply":"2024-05-13T20:36:42.848573Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"classifier2(sequences2)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:42.850904Z","iopub.execute_input":"2024-05-13T20:36:42.851194Z","iopub.status.idle":"2024-05-13T20:36:43.143338Z","shell.execute_reply.started":"2024-05-13T20:36:42.851171Z","shell.execute_reply":"2024-05-13T20:36:43.142340Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'label': 'NEGATIVE', 'score': 0.9971033930778503}]"},"metadata":{}}]},{"cell_type":"code","source":"classifier3 = pipeline(\"sentiment-analysis\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:43.146528Z","iopub.execute_input":"2024-05-13T20:36:43.147119Z","iopub.status.idle":"2024-05-13T20:36:43.383096Z","shell.execute_reply.started":"2024-05-13T20:36:43.147093Z","shell.execute_reply":"2024-05-13T20:36:43.382067Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"}]},{"cell_type":"code","source":"sequences3 = [\"\"\"stallations of wind energy infrastructure were up 50% last year compared to 2022, making it a record year for the industry globally.\n\nSome 117GW of new capacity was installed in 54 countries, according to analysis by the Global Wind Energy Council (GWEC). Gathering momentum in offshore wind and promising outlooks in developing countries mean the organisation has revised its 2024-2030 growth forecast upwards by around 10%.\n\nHowever, the GWEC said that policymakers and industry need to unlock more growth to stay on the net-zero pathway.\n\n“Growth is highly concentrated in a few big countries like China, the US, Brazil and Germany, and we need many more countries to remove barriers and improve market frameworks to scale up wind installations,” said GWEC CEO Ben Backwell.\n\"\"\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:43.384134Z","iopub.execute_input":"2024-05-13T20:36:43.384416Z","iopub.status.idle":"2024-05-13T20:36:43.389091Z","shell.execute_reply.started":"2024-05-13T20:36:43.384392Z","shell.execute_reply":"2024-05-13T20:36:43.388151Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"classifier3(sequences3)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:43.390115Z","iopub.execute_input":"2024-05-13T20:36:43.390449Z","iopub.status.idle":"2024-05-13T20:36:43.487423Z","shell.execute_reply.started":"2024-05-13T20:36:43.390425Z","shell.execute_reply":"2024-05-13T20:36:43.486647Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.939201295375824}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Summerization","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n# Create a text summarization pipeline\nsummarization_pipeline = pipeline(\"summarization\")\n\n# Example usage\ntext = \"Installations of wind energy infrastructure were up 50% last year compared to 2022, making it a record year for the industry globally.\"\nresult = summarization_pipeline(text)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:43.490315Z","iopub.execute_input":"2024-05-13T20:36:43.490776Z","iopub.status.idle":"2024-05-13T20:36:56.746979Z","shell.execute_reply.started":"2024-05-13T20:36:43.490749Z","shell.execute_reply":"2024-05-13T20:36:56.746011Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ccf4da1e3674f758dadcc992f1f2f2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b29b52a89b964fee867beb2a22a4709a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8c6b4a8adf462583d370384f05b060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82c646804f8c43f2a76b4f0406213e10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bba5e663528444eb8c93d47ba0c2523"}},"metadata":{}},{"name":"stderr","text":"Your max_length is set to 142, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n","output_type":"stream"},{"name":"stdout","text":"[{'summary_text': \" Installations of wind energy infrastructure were up 50% last year compared to 2022, making it a record year for the industry globally . Wind energy infrastructure infrastructure was up 50 per cent last year, according to the World's Wind Energy Network . The wind energy industry is expected to be a global boom in wind power development in the coming years .\"}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Question-Answering","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Create a question answering pipeline\nquestion_answering_pipeline = pipeline(\"question-answering\")\n\n# Example usage\ncontext = \"Hugging Face is a company that provides state-of-the-art natural language processing technologies.\"\nquestion = \"What does Hugging Face do?\"\nresult = question_answering_pipeline(question=question, context=context)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:36:56.748199Z","iopub.execute_input":"2024-05-13T20:36:56.748938Z","iopub.status.idle":"2024-05-13T20:37:00.521873Z","shell.execute_reply.started":"2024-05-13T20:36:56.748911Z","shell.execute_reply":"2024-05-13T20:37:00.520852Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16b9572c94e94ced860bc399b33d319c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97903391532041b9b011fd42a5658534"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b748b14edc24ae78686064c0a313545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b390325cf184ed886775fb229e7be93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3478aa8452814a24b59218119b9a3b6c"}},"metadata":{}},{"name":"stdout","text":"{'score': 0.7119643688201904, 'start': 31, 'end': 97, 'answer': 'provides state-of-the-art natural language processing technologies'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Text Generation","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Create a text generation pipeline\ntext_generation_pipeline = pipeline(\"text-generation\")\n\n# Example usage\nprompt = \"Once upon a time,\"\nresult = text_generation_pipeline(prompt, max_length=50, num_return_sequences=5)\nfor i, res in enumerate(result, 1):\n    print(f\"Generated Text {i}: {res['generated_text']}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:37:00.523948Z","iopub.execute_input":"2024-05-13T20:37:00.524261Z","iopub.status.idle":"2024-05-13T20:37:08.038282Z","shell.execute_reply.started":"2024-05-13T20:37:00.524234Z","shell.execute_reply":"2024-05-13T20:37:08.037299Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"571a6b72f2454ee2905d58895f5bf4b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72291f2e320a4064a98a0a3955440908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92b56692be244c0ab96183852c51e74f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5b6bef7ab064815a2078c31774a74e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f751cfe18fd74e21bdc685dbef1b79a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc8436f0b0fd48648307ebd36602fccc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3b1e26d5e824ff6b3cb289a4ec48aaf"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Text 1: Once upon a time, we were given to believe all things contained within the veil, and we believed in what has been said in this passage; and then our understanding was strengthened in this passage, by the understanding of Christ, because we believed in what\nGenerated Text 2: Once upon a time, he was the sole protector of the universe's strongest heroes. He never stopped working after he saw himself take up the mantle of Thor for Asgard and joined the Dark Gods Thora, Loki, and Asgrim in a long-\nGenerated Text 3: Once upon a time, she told him, the place was an endless desert. The two looked forward and up from the ceiling in anticipation of his visit.\n\n\"Who are you?\"\n\n\"I am the one who made this place,\"\nGenerated Text 4: Once upon a time, it was said, the men went round and out of the garden, leaving the horses in their quarters.\n\n[Pg 476]\n\n1786.—With that knowledge of the things being done, they came together\nGenerated Text 5: Once upon a time, an unceasing torrent of grief and contempt for the people had filled the city. And the most terrible of evils: That a king could not yet receive power. And a man and a slave's rights. And, before\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\n\ntext_generator = pipeline(\"text-generation\")\nprint(text_generator(\"As far as I am concerned, I will\", max_length=50, do_sample=False))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:37:08.039451Z","iopub.execute_input":"2024-05-13T20:37:08.039778Z","iopub.status.idle":"2024-05-13T20:37:10.139088Z","shell.execute_reply.started":"2024-05-13T20:37:08.039748Z","shell.execute_reply":"2024-05-13T20:37:10.138337Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[{'generated_text': 'As far as I am concerned, I will be the first to admit that I am not a fan of the idea of a \"free market.\" I think that the idea of a free market is a bit of a stretch. I think that the idea'}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Translation","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator = pipeline(\"translation_en_to_de\")\nprint(translator(\"Hugging Face is a technology company based in New York and Paris\", max_length=40))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:37:10.140111Z","iopub.execute_input":"2024-05-13T20:37:10.140836Z","iopub.status.idle":"2024-05-13T20:37:12.458034Z","shell.execute_reply.started":"2024-05-13T20:37:10.140809Z","shell.execute_reply":"2024-05-13T20:37:12.454409Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"name":"stdout","text":"[{'translation_text': 'Hugging Face ist ein Technologieunternehmen mit Sitz in New York und Paris.'}]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Named Entity Recognition (NER) ","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nner_pipe = pipeline(\"ner\")\n\nsequence = \"\"\"FOR ANKIT Kumar, 21, a state-ranked hurdler, life is an unending race against time. When not trying to beat his coach’s stop-watch at the Jawaharlal Nehru (JLN) Stadium, he is trying to stick to the ETA while delivering orders for a quick-commerce grocery app.\n\nThe son of a welder from Kundli in Haryana, Ankit stays in a windowless room at Kotla Mubarakpur, an urban slum not far from JLN. It’s a space that he shares with four others. Ankit’s roommates and close to 1,000 other athletes at Kotla lead a similar double-life. They fund their track-and-field dreams by working as gig workers — the flexibility and independence of the industry allowing them time to move between two very distinct worlds.\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:37:12.459683Z","iopub.execute_input":"2024-05-13T20:37:12.460430Z","iopub.status.idle":"2024-05-13T20:37:20.335000Z","shell.execute_reply.started":"2024-05-13T20:37:12.460399Z","shell.execute_reply":"2024-05-13T20:37:20.334268Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"585445366e33450186023ad8a8ab332e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f650bb7475f4e07ab06d91e588a61a2"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1747673ab46a4a4fad0615b5687b3281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d70917320ad459fa4ad092fda2dca9a"}},"metadata":{}}]},{"cell_type":"code","source":"for entity in ner_pipe(sequence):\n    print(entity)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:37:20.336100Z","iopub.execute_input":"2024-05-13T20:37:20.336438Z","iopub.status.idle":"2024-05-13T20:37:21.035185Z","shell.execute_reply.started":"2024-05-13T20:37:20.336406Z","shell.execute_reply":"2024-05-13T20:37:21.034271Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"{'entity': 'I-PER', 'score': 0.9981433, 'index': 3, 'word': 'AN', 'start': 4, 'end': 6}\n{'entity': 'I-PER', 'score': 0.99586177, 'index': 4, 'word': '##K', 'start': 6, 'end': 7}\n{'entity': 'I-PER', 'score': 0.998384, 'index': 5, 'word': '##IT', 'start': 7, 'end': 9}\n{'entity': 'I-PER', 'score': 0.99970216, 'index': 6, 'word': 'Kumar', 'start': 10, 'end': 15}\n{'entity': 'I-LOC', 'score': 0.9842407, 'index': 41, 'word': 'J', 'start': 138, 'end': 139}\n{'entity': 'I-LOC', 'score': 0.98074186, 'index': 42, 'word': '##awa', 'start': 139, 'end': 142}\n{'entity': 'I-LOC', 'score': 0.99273247, 'index': 43, 'word': '##har', 'start': 142, 'end': 145}\n{'entity': 'I-LOC', 'score': 0.99391407, 'index': 44, 'word': '##lal', 'start': 145, 'end': 148}\n{'entity': 'I-LOC', 'score': 0.99490404, 'index': 45, 'word': 'Nehru', 'start': 149, 'end': 154}\n{'entity': 'I-LOC', 'score': 0.93315995, 'index': 47, 'word': 'J', 'start': 156, 'end': 157}\n{'entity': 'I-LOC', 'score': 0.92576474, 'index': 48, 'word': '##L', 'start': 157, 'end': 158}\n{'entity': 'I-LOC', 'score': 0.928079, 'index': 49, 'word': '##N', 'start': 158, 'end': 159}\n{'entity': 'I-LOC', 'score': 0.990144, 'index': 51, 'word': 'Stadium', 'start': 161, 'end': 168}\n{'entity': 'I-ORG', 'score': 0.9736963, 'index': 60, 'word': 'ET', 'start': 199, 'end': 201}\n{'entity': 'I-ORG', 'score': 0.93373436, 'index': 61, 'word': '##A', 'start': 201, 'end': 202}\n{'entity': 'I-LOC', 'score': 0.9971679, 'index': 80, 'word': 'Ku', 'start': 287, 'end': 289}\n{'entity': 'I-LOC', 'score': 0.95037615, 'index': 81, 'word': '##nd', 'start': 289, 'end': 291}\n{'entity': 'I-LOC', 'score': 0.9911135, 'index': 82, 'word': '##li', 'start': 291, 'end': 293}\n{'entity': 'I-LOC', 'score': 0.99734676, 'index': 84, 'word': 'Haryana', 'start': 297, 'end': 304}\n{'entity': 'I-PER', 'score': 0.9992855, 'index': 86, 'word': 'An', 'start': 306, 'end': 308}\n{'entity': 'I-PER', 'score': 0.99713254, 'index': 87, 'word': '##ki', 'start': 308, 'end': 310}\n{'entity': 'I-PER', 'score': 0.9987161, 'index': 88, 'word': '##t', 'start': 310, 'end': 311}\n{'entity': 'I-LOC', 'score': 0.998271, 'index': 96, 'word': 'Ko', 'start': 342, 'end': 344}\n{'entity': 'I-LOC', 'score': 0.9942748, 'index': 97, 'word': '##tl', 'start': 344, 'end': 346}\n{'entity': 'I-LOC', 'score': 0.99656963, 'index': 98, 'word': '##a', 'start': 346, 'end': 347}\n{'entity': 'I-LOC', 'score': 0.9990767, 'index': 99, 'word': 'Mu', 'start': 348, 'end': 350}\n{'entity': 'I-LOC', 'score': 0.9953139, 'index': 100, 'word': '##bara', 'start': 350, 'end': 354}\n{'entity': 'I-LOC', 'score': 0.9789873, 'index': 101, 'word': '##k', 'start': 354, 'end': 355}\n{'entity': 'I-LOC', 'score': 0.99411666, 'index': 102, 'word': '##pur', 'start': 355, 'end': 358}\n{'entity': 'I-LOC', 'score': 0.92219615, 'index': 111, 'word': 'J', 'start': 387, 'end': 388}\n{'entity': 'I-LOC', 'score': 0.7942014, 'index': 112, 'word': '##L', 'start': 388, 'end': 389}\n{'entity': 'I-LOC', 'score': 0.795871, 'index': 113, 'word': '##N', 'start': 389, 'end': 390}\n{'entity': 'I-PER', 'score': 0.9990295, 'index': 127, 'word': 'An', 'start': 438, 'end': 440}\n{'entity': 'I-PER', 'score': 0.99494994, 'index': 128, 'word': '##ki', 'start': 440, 'end': 442}\n{'entity': 'I-PER', 'score': 0.99742126, 'index': 129, 'word': '##t', 'start': 442, 'end': 443}\n{'entity': 'I-LOC', 'score': 0.9955395, 'index': 143, 'word': 'Ko', 'start': 493, 'end': 495}\n{'entity': 'I-LOC', 'score': 0.9912243, 'index': 144, 'word': '##tl', 'start': 495, 'end': 497}\n{'entity': 'I-LOC', 'score': 0.9892512, 'index': 145, 'word': '##a', 'start': 497, 'end': 498}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Fill-Mask","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Create a fill-mask pipeline\nfill_masker = pipeline(\"fill-mask\")\n\n# Input sentence with a masked token\ninput_sentence = \"Here’s what a 100-gram <mask> of persimmon contains.\"\n\n# Use the pipeline to fill in the masked token\nfilled_sentence = fill_masker(input_sentence)\n\n# Output the predictions\nfor result in filled_sentence:\n    print(result)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T20:37:21.036464Z","iopub.execute_input":"2024-05-13T20:37:21.036916Z","iopub.status.idle":"2024-05-13T20:37:24.126516Z","shell.execute_reply.started":"2024-05-13T20:37:21.036882Z","shell.execute_reply":"2024-05-13T20:37:24.125502Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ada29018adf4c56b88b8cde4d97911c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a13a4a16d594f9d80e2e04de216b2a6"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d87058fc6694b518fade0d1b0df215c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d181bd359174334b67544ddb2134373"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8443a8d518564fdb89462b0dd0dcc1c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"398c175ddb484cdd97605c4040cee72a"}},"metadata":{}},{"name":"stdout","text":"{'score': 0.3683781325817108, 'token': 7304, 'token_str': ' bottle', 'sequence': 'Here’s what a 100-gram bottle of persimmon contains.'}\n{'score': 0.09641332179307938, 'token': 29635, 'token_str': ' packet', 'sequence': 'Here’s what a 100-gram packet of persimmon contains.'}\n{'score': 0.07851327955722809, 'token': 25413, 'token_str': ' jar', 'sequence': 'Here’s what a 100-gram jar of persimmon contains.'}\n{'score': 0.06427302956581116, 'token': 3298, 'token_str': ' bag', 'sequence': 'Here’s what a 100-gram bag of persimmon contains.'}\n{'score': 0.022608458995819092, 'token': 5749, 'token_str': ' bowl', 'sequence': 'Here’s what a 100-gram bowl of persimmon contains.'}\n","output_type":"stream"}]}]}